{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = statsmodels.api.datasets.get_rdataset('mtcars').data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['mpg'])\n",
    "y = data['mpg'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleçao de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo(x, w_):\n",
    "    return x @ w_\n",
    "\n",
    "def weights_bias(X:np.ndarray, y:np.ndarray):\n",
    "    return np.linalg.inv( np.dot(X.T, X) ) @ X.T @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35082641,  0.01354278, -0.02054767,  1.24158213, -3.8261315 ,\n",
       "         1.19139689,  0.18972068,  2.8322223 ,  1.05426253, -0.26321386]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pesos = weights_bias(X.values, y)\n",
    "pesos.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[22.43607595],\n",
       "        [22.12759467]]),\n",
       " array([[21.],\n",
       "        [21.]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo(X.values, pesos)[0:2, :],y[0:2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backwardEliminação(X, y, data, target_name='mpg', significancia=0.05):\n",
    "    AIC = np.inf\n",
    "    columnsList = data.drop(columns=[target_name]).columns.tolist()\n",
    "    ant_ = len(columnsList)\n",
    "\n",
    "    for col in data.columns:\n",
    "        model = statsmodels.api.OLS(y, X[columnsList].values).fit()\n",
    "        \n",
    "        strCol = ' '.join(columnsList) + \" | AIC=\"\n",
    "        if len(columnsList) == ant_:\n",
    "            print(f'{strCol}{round(model.aic, 2)}')\n",
    "\n",
    "        index = pd.Series(model.pvalues).idxmax()\n",
    "        \n",
    "        if model.pvalues[index] > significancia:\n",
    "            print(f'Remove {columnsList[index]}')\n",
    "            del columnsList[index]\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cyl disp hp drat wt qsec vs am gear carb | AIC=160.36\n",
      "Remove vs\n",
      "Remove carb\n",
      "Remove cyl\n",
      "Remove gear\n",
      "Remove hp\n",
      "Remove drat\n",
      "Remove disp\n"
     ]
    }
   ],
   "source": [
    "model = backwardEliminação(X, y, data, significancia=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.987</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.986</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   741.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 10 Nov 2024</td> <th>  Prob (F-statistic):</th>          <td>1.71e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:40:44</td>     <th>  Log-Likelihood:    </th>          <td> -73.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th>          <td>   152.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    29</td>      <th>  BIC:               </th>          <td>   156.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>   -3.1855</td> <td>    0.483</td> <td>   -6.598</td> <td> 0.000</td> <td>   -4.173</td> <td>   -2.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>    1.5998</td> <td>    0.102</td> <td>   15.665</td> <td> 0.000</td> <td>    1.391</td> <td>    1.809</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>    4.2995</td> <td>    1.024</td> <td>    4.198</td> <td> 0.000</td> <td>    2.205</td> <td>    6.394</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.348</td> <th>  Durbin-Watson:     </th> <td>   1.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.309</td> <th>  Jarque-Bera (JB):  </th> <td>   1.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.177</td> <th>  Prob(JB):          </th> <td>   0.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.057</td> <th>  Cond. No.          </th> <td>    43.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared (uncentered):}      &     0.987   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.986   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       }          &     741.0   \\\\\n",
       "\\textbf{Date:}             & Sun, 10 Nov 2024 & \\textbf{  Prob (F-statistic):}          &  1.71e-27   \\\\\n",
       "\\textbf{Time:}             &     10:40:44     & \\textbf{  Log-Likelihood:    }          &   -73.115   \\\\\n",
       "\\textbf{No. Observations:} &          32      & \\textbf{  AIC:               }          &     152.2   \\\\\n",
       "\\textbf{Df Residuals:}     &          29      & \\textbf{  BIC:               }          &     156.6   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "            & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{x1} &      -3.1855  &        0.483     &    -6.598  &         0.000        &       -4.173    &       -2.198     \\\\\n",
       "\\textbf{x2} &       1.5998  &        0.102     &    15.665  &         0.000        &        1.391    &        1.809     \\\\\n",
       "\\textbf{x3} &       4.2995  &        1.024     &     4.198  &         0.000        &        2.205    &        6.394     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  2.348 & \\textbf{  Durbin-Watson:     } &    1.861  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.309 & \\textbf{  Jarque-Bera (JB):  } &    1.351  \\\\\n",
       "\\textbf{Skew:}          &  0.177 & \\textbf{  Prob(JB):          } &    0.509  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.057 & \\textbf{  Cond. No.          } &     43.8  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.987\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.986\n",
       "Method:                 Least Squares   F-statistic:                              741.0\n",
       "Date:                Sun, 10 Nov 2024   Prob (F-statistic):                    1.71e-27\n",
       "Time:                        10:40:44   Log-Likelihood:                         -73.115\n",
       "No. Observations:                  32   AIC:                                      152.2\n",
       "Df Residuals:                      29   BIC:                                      156.6\n",
       "Df Model:                           3                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -3.1855      0.483     -6.598      0.000      -4.173      -2.198\n",
       "x2             1.5998      0.102     15.665      0.000       1.391       1.809\n",
       "x3             4.2995      1.024      4.198      0.000       2.205       6.394\n",
       "==============================================================================\n",
       "Omnibus:                        2.348   Durbin-Watson:                   1.861\n",
       "Prob(Omnibus):                  0.309   Jarque-Bera (JB):                1.351\n",
       "Skew:                           0.177   Prob(JB):                        0.509\n",
       "Kurtosis:                       2.057   Cond. No.                         43.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularização L1 Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo(x, weights, bias):\n",
    "    return tf.matmul(x, weights) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_loss(ytrue:tf.Tensor, ypred:tf.Tensor):\n",
    "    return tf.reduce_mean(\n",
    "        tf.pow((ytrue - ypred), 2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X.values.astype(np.float32)\n",
    "y_ = y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = (X_ - X_.mean(axis=0))/X_.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X_, y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = dataset\\\n",
    "        .batch(batch_size=32)\\\n",
    "        .shuffle(buffer_size=10, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      " =>loss : 438.82| l1: 0.00\n",
      "Epoch : 1\n",
      " =>loss : 395.65| l1: 0.16\n",
      "Epoch : 2\n",
      " =>loss : 341.85| l1: 0.36\n",
      "Epoch : 3\n",
      " =>loss : 284.30| l1: 0.57\n",
      "Epoch : 4\n",
      " =>loss : 227.80| l1: 0.77\n",
      "Epoch : 5\n",
      " =>loss : 174.97| l1: 0.93\n",
      "Epoch : 6\n",
      " =>loss : 127.08| l1: 1.05\n",
      "Epoch : 7\n",
      " =>loss : 85.15| l1: 1.11\n",
      "Epoch : 8\n",
      " =>loss : 50.65| l1: 1.12\n",
      "Epoch : 9\n",
      " =>loss : 25.56| l1: 1.07\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed( seed = 1 )\n",
    "# pesos\n",
    "weights = tf.Variable(\n",
    "    tf.zeros((10, 1)), dtype=tf.float32\n",
    "    )\n",
    "# bias\n",
    "bias = tf.Variable(\n",
    "    [[0]], dtype=tf.float32\n",
    "    )\n",
    "\n",
    "optim = keras.optimizers.SGD(learning_rate=0.01, momentum=0.99, nesterov=True)\n",
    "lambda_ = 0.1\n",
    "\n",
    "for epoch in range(10):\n",
    "    for xbatch, ybatch in train_:\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = modelo(xbatch, weights, bias)\n",
    "\n",
    "            # Expandindo  \n",
    "            tensor_ = tf.tile(bias, [10,1])\n",
    "            weights_i = tf.concat([weights, tensor_], axis=0)[:11, :]\n",
    "\n",
    "            # Penalidade lambda * SUM |Wi|\n",
    "            L1 = lambda_ * tf.reduce_sum(tf.abs(weights))\n",
    "            \n",
    "            # calculando a perda\n",
    "            loss = MSE_loss(ybatch, pred) + L1\n",
    "        \n",
    "        # adicioando o gradient\n",
    "        gradient = tape.gradient(loss, [weights, bias])\n",
    "        optim.apply_gradients(\n",
    "            zip(gradient, [weights, bias])\n",
    "        )\n",
    "    print(f'Epoch : {epoch}\\n =>loss : {loss:.2f}| l1: {L1:.2f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=(10, 1) dtype=float32, numpy=\n",
       " array([[-1.1231992 ],\n",
       "        [-1.1466397 ],\n",
       "        [-1.182853  ],\n",
       "        [ 0.9152894 ],\n",
       "        [-1.5939044 ],\n",
       "        [ 0.37498504],\n",
       "        [ 0.69366896],\n",
       "        [ 1.1014943 ],\n",
       "        [ 0.6130859 ],\n",
       "        [-1.125236  ]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 1) dtype=float32, numpy=array([[19.290466]], dtype=float32)>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = modelo(X_, weights, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(10.844315)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.691826343536377"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_, pred.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "\t=>loss : 438.82 & l1: 0.00\n",
      "Epoch : 1\n",
      "\t=>loss : 395.54 & l1: 0.05\n",
      "Epoch : 2\n",
      "\t=>loss : 341.74 & l1: 0.27\n",
      "Epoch : 3\n",
      "\t=>loss : 284.42 & l1: 0.68\n",
      "Epoch : 4\n",
      "\t=>loss : 228.25 & l1: 1.24\n",
      "Epoch : 5\n",
      "\t=>loss : 175.63 & l1: 1.81\n",
      "Epoch : 6\n",
      "\t=>loss : 127.69 & l1: 2.27\n",
      "Epoch : 7\n",
      "\t=>loss : 85.46 & l1: 2.52\n",
      "Epoch : 8\n",
      "\t=>loss : 50.58 & l1: 2.52\n",
      "Epoch : 9\n",
      "\t=>loss : 25.23 & l1: 2.32\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed( seed = 1 )\n",
    "# pesos\n",
    "weights = tf.Variable(\n",
    "    tf.zeros((10, 1)), dtype=tf.float32\n",
    "    )\n",
    "# bias\n",
    "bias = tf.Variable(\n",
    "    [[0]], dtype=tf.float32\n",
    "    )\n",
    "\n",
    "optim = keras.optimizers.SGD(learning_rate=0.01, momentum=0.99, nesterov=True)\n",
    "lambda_ = 0.20\n",
    "\n",
    "for epoch in range(10):\n",
    "    for xbatch, ybatch in train_:\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = modelo(xbatch, weights, bias)\n",
    "\n",
    "            # Expandindo  \n",
    "            tensor_ = tf.tile(bias, [10,1])\n",
    "            weights_i = tf.concat([weights, tensor_], axis=0)[:11, :]\n",
    "\n",
    "            # Penalidade lambda * SUM |Wi|\n",
    "            L1 = lambda_ * tf.reduce_sum(tf.pow(weights, 2))\n",
    "            \n",
    "            # calculando a perda\n",
    "            loss = MSE_loss(ybatch, pred) + L1\n",
    "        \n",
    "        # adicioando o gradient\n",
    "        gradient = tape.gradient(loss, [weights, bias])\n",
    "        optim.apply_gradients(\n",
    "            zip(gradient, [weights, bias])\n",
    "        )\n",
    "    print(f'Epoch : {epoch}\\n\\t=>loss : {loss:.2f} & l1: {L1:.2f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(10, 1) dtype=float32, numpy=\n",
       "array([[-1.0646281 ],\n",
       "       [-1.0882386 ],\n",
       "       [-1.1273296 ],\n",
       "       [ 0.87819165],\n",
       "       [-1.5153953 ],\n",
       "       [ 0.37788078],\n",
       "       [ 0.6662864 ],\n",
       "       [ 1.0623733 ],\n",
       "       [ 0.6029124 ],\n",
       "       [-1.0876013 ]], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = modelo(X_, weights, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(9.510708)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7297247648239136"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_, pred.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
